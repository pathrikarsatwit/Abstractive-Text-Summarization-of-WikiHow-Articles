{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0Oew8JF8xQg"
      },
      "source": [
        "# Data Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341,
          "referenced_widgets": [
            "49d866ca4d894a64a1f873d295c8c08d",
            "eaa39bec1dae48f080de98bf5233023d",
            "ca5e9d787d60472ab70a603c0b287cc4",
            "fc4fcb02211d47baa2222c780c42f137",
            "aec9e26f2b7b4ab5842342d8d56e4a41",
            "4a3b646736a844a8ae9e2458c51d2ca5",
            "90b0f598febd45c1adfe663c2b33c86e",
            "7699f7457b274afc8cefe280382de29e",
            "e0b4b99ba4934c7b80a719d1e5b22cde",
            "43d627b027ff4914a7804a27ad24e9f6",
            "592d371b923b4591a1ee942e3be8ca03",
            "a5c967c2531449fbbec615bf56c08218",
            "b572801f7f604dc490d832ae9a95be22",
            "12a877447ad94d3c86477a2b6170a933",
            "90b754bca5da4124bb7931986630c54c",
            "e588d78e87994151800601e48836df19",
            "5b3c34438e274aaab41c1eef393ccc5a",
            "b1c84fa1efd7415e8bb6a639b6d9b57f",
            "7a8f277d4d5f4e00ba124e5eeedb9665",
            "4c66999a59274c29b2786276e884f4c7",
            "86879ae8e2b0453b8a4b03563f0a5eaa",
            "61ddd751029d44219758756781169ff1",
            "1cbc2ce878f24b8cb3664caa1e85664c",
            "cfb59879f72946c293f2ece29c054ba8",
            "17ea5b722bd44200a4f2125b06d9e450",
            "a023c573c7dd4914a3d33af04f8f3c3a",
            "0721f356da2d4bf294871bbc823e07e2",
            "c9f377ef336b46d592f3c031979f73e0",
            "c3fe51c66593464cbee322f1555d94e4",
            "7cce2e59129143589457a899fd5f4e18",
            "4231edb2c3db44e9848e1a6f5681b198",
            "26ca435ef32c4251b4a402db064fb2c2",
            "7d88c5998f4342ceb727b1a00e6bb1b9"
          ]
        },
        "collapsed": true,
        "id": "uftDMYMxFYOC",
        "outputId": "2cd3a54c-93e0-4509-a809-9af4a3f7deae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49d866ca4d894a64a1f873d295c8c08d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/792 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5c967c2531449fbbec615bf56c08218",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "wikihow-cleaned.csv:   0%|          | 0.00/619M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1cbc2ce878f24b8cb3664caa1e85664c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/214293 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['summary', 'title', 'text'],\n",
            "        num_rows: 214293\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"gursi26/wikihow-cleaned\")\n",
        "print(ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R29jl6BK80pY"
      },
      "source": [
        "# Feature Engineering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TOYN3ZPtJiZe"
      },
      "outputs": [],
      "source": [
        "input = ds[\"train\"][\"text\"]\n",
        "target = ds[\"train\"][\"summary\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0yZAQkRSbBm",
        "outputId": "233cd3f1-621f-4fef-eca7-ae686ecd2f1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Main set size: X: 182149, Y: 182149\n",
            "Training set size: X: 150005 , Y: 150005\n",
            "Validation set size: 32144, Y: 32144\n",
            "Test set size: 32144, Y: 32144\n",
            "<class 'list'>\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = list(input)\n",
        "y = list(target)\n",
        "X_main, X_test, y_main, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_main, y_main, test_size=(0.15 / (1 - 0.15)), random_state=42)\n",
        "print(f\"Main set size: X: {len(X_main)}, Y: {len(y_main)}\")\n",
        "print(f\"Training set size: X: {len(X_train)} , Y: {len(y_train)}\")\n",
        "print(f\"Validation set size: {len(X_val)}, Y: {len(y_val)}\")\n",
        "print(f\"Test set size: {len(X_test)}, Y: {len(y_test)}\")\n",
        "print(type(X_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dMyagp1M5PVa"
      },
      "outputs": [],
      "source": [
        "X_train = [str(x) for x in X_train]\n",
        "X_val = [str(x) for x in X_val]\n",
        "X_test = [str(x) for x in X_test]\n",
        "\n",
        "y_train = [str(y) for y in y_train]\n",
        "y_val = [str(y) for y in y_val]\n",
        "y_test = [str(y) for y in y_test]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150,
          "referenced_widgets": [
            "7bbd3bd0edbb4f808dd22a8e8fc4cfaa",
            "98c5bfd58672440aa2609a127cfaa4ed",
            "4d27f6a552f54596ab27db2696558640",
            "dddb7a83533048e2adb23905d5a0d027",
            "631812c64f5b47909ccfc89b6c4ef8f7",
            "c7f0fd6088444169943414e94962dc7f",
            "5779047a01284aa68c4e319689497d3b",
            "a4f41f2ef6e3400baa336d91215af90d",
            "491a559e82b24b7b896e5f9e36f102e2",
            "9ebf7ca9d656429ba405941c662b46dc",
            "aae2e43734574045aceecf407d1d13cc",
            "192adcf668e740bbba101308a0c4af4c",
            "aa8812904f8c4460960bb597c31f06e4",
            "7ec8ecbc5c5645f5889afe26bf676065",
            "e68f3416d7fe438eb61db802b6d9ed03",
            "5e26b282a1a2422ebcaf3af5f260fde1",
            "38deb684f7fb41d78940755db25236d8",
            "fea48add12794551a0aa65f62fbdb1ea",
            "bc3667c4966a4cf2810346adc0db35f5",
            "c5fd01900def49f5bb1a81554c87a848",
            "319c47e011c041c7918aefc6cc0c0b90",
            "2a21ec1186de45cbaadddfb162a4c176",
            "34222f14b02e4ac5957fd1b15531b3f6",
            "48f27ef13518413fae187a7dde0e908d",
            "89c3c91f396d408fb70a6aeea19f1e13",
            "0d60185a46934483a926f89c74ade205",
            "9f1c46284771435b8e6579c5704c841f",
            "83ec95e7b74c47298ccebe1c0a26e40c",
            "ab2e12319d0944a8a9540bedeecf96c6",
            "2329c069d6a3468a8cda5878e9905498",
            "2780a672253a43209bd57170b7c3194c",
            "118e793ec02643fcb398d240b0ff78c3",
            "06148090c8be49bdad1b5cda374b94e2"
          ]
        },
        "id": "2nqd2yhjz1eP",
        "outputId": "b52dae20-3e2e-4444-a142-ae0ddc8e4198"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bbd3bd0edbb4f808dd22a8e8fc4cfaa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "192adcf668e740bbba101308a0c4af4c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "34222f14b02e4ac5957fd1b15531b3f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        }
      ],
      "source": [
        "from transformers import T5Tokenizer\n",
        "\n",
        "# Load T5-small tokenizer\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
        "\n",
        "# Add \"summarize: \" prefix to inputs\n",
        "def tokenize_batch(texts, summaries, max_input_length=256, max_output_length=128):\n",
        "    texts = [\"summarize: \" + t for t in texts]\n",
        "\n",
        "    model_inputs = tokenizer(\n",
        "        texts,\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    labels = tokenizer(\n",
        "        summaries,\n",
        "        max_length=max_output_length,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n",
        "\n",
        "# Tokenize datasets\n",
        "train_enc = tokenize_batch(X_train, y_train)\n",
        "val_enc   = tokenize_batch(X_val, y_val)\n",
        "test_enc  = tokenize_batch(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UvWEalEydwHZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class T5Dataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
        "\n",
        "# Create dataset objects\n",
        "train_dataset = T5Dataset(train_enc)\n",
        "val_dataset   = T5Dataset(val_enc)\n",
        "test_dataset  = T5Dataset(test_enc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ief1KlpK89a1"
      },
      "source": [
        "# Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "0385ee31f13e4d7d97cca47c92b7336a",
            "503d8e3d6b3a4494b377fb88e426ed00",
            "7f00f876cd1345c99be28afa92fe3ab8",
            "2168a42228e843b2b6125c32116c1e39",
            "7ce5f9593d4a4af1a4b5df5252130205",
            "ec032325127448559a7881596eac7c2d",
            "3c72bee9a12d492685b222e07fc9766b",
            "3a34f4da89364dde89c4a69cb3ba60d7",
            "d8e9850ff01c44908a11b42985bae194",
            "d4366443e54f43fe83ef42fdd09bbcd8",
            "bf5215d037e24568813aa9b5a9a9ba72",
            "a291cf8285ff43778014cc8ed4b85487",
            "41b993a5e279470fa5251fff0348ba71",
            "c909e04365484ff18009e54096cd16e9",
            "35232d5d5fa8444b88da934ec7136cda",
            "7a3f6e1d31914649b5df31227ca60db6",
            "8edc03cac29e4c10ae37e54d88167a9d",
            "042728abb087493e929867c33ad5fcc7",
            "9ddcdbc61b8149dda1908458020fa647",
            "0d7ca70d7b344d7d91470a9720cea1e7",
            "25a7e4989126444db5ca6415d5bb7a6b",
            "dcdf400681254baeb87f3c7930e42ac5",
            "a09a2c1736234523ad104df26ca0a74a",
            "376145467e8e4400a2659ef2f049f28a",
            "4f3574d6165d4293be4d63b637185012",
            "2bf2fdf6f4bc48bf894d89056d6165b2",
            "3488defe706848cbbc1463811bfa6536",
            "cc9168e050894335a7f9dde874cac8b7",
            "0815b44cd6c54cfaabf0292741397e1e",
            "4e1cc778b74247bfa66c780a10560685",
            "c0e433688d97485b83a26d61182a20ca",
            "a3cabe18441e4c37a7a6684860847e15",
            "6325ac08cb6c46b8bb2f9a157f571561"
          ]
        },
        "id": "IW8bafIm9rAC",
        "outputId": "c55de55e-0e2c-4fcc-e1f8-3a65d4806958"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0385ee31f13e4d7d97cca47c92b7336a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a291cf8285ff43778014cc8ed4b85487",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a09a2c1736234523ad104df26ca0a74a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import T5ForConditionalGeneration\n",
        "\n",
        "# Load T5-small model\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUZ77w5d9BCd"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Q7zF0knjfi1P"
      },
      "outputs": [],
      "source": [
        "# from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir=\"./t5-small-finetuned\",\n",
        "#     per_device_train_batch_size=8,   # can adjust based on GPU memory\n",
        "#     per_device_eval_batch_size=8,\n",
        "#     num_train_epochs=2,\n",
        "#     eval_strategy=\"epoch\",\n",
        "#     save_strategy=\"epoch\",\n",
        "#     logging_steps=50,\n",
        "#     fp16=True                       # use mixed precision for speed\n",
        "#     # Removed predict_with_generate=True as it is causing a TypeError\n",
        "# )\n",
        "\n",
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=train_dataset,\n",
        "#     eval_dataset=val_dataset,\n",
        "#     tokenizer=tokenizer\n",
        "# )\n",
        "# trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "j5pOjYDgE4If"
      },
      "outputs": [],
      "source": [
        "# model.save_pretrained(\"t5-finetuned-xsum\")\n",
        "# tokenizer.save_pretrained(\"t5Q267-finetuned-xsum\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "myYT6WhqEvkV"
      },
      "outputs": [],
      "source": [
        "# !pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ws0Q_JQhEy1c"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import login\n",
        "# login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "SswsfOtzFUPX"
      },
      "outputs": [],
      "source": [
        "# # Push the model\n",
        "# model.push_to_hub(\"Sakshi-1234/NLPFinal\")\n",
        "# # Push the tokenizer\n",
        "# tokenizer.push_to_hub(\"Sakshi-1234/NLPFinal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLq-UWzw9JJh"
      },
      "source": [
        "# Inference Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258,
          "referenced_widgets": [
            "4a609cb765cd4cddb4e11d0d00eac7de",
            "4b22ddade11446bfbd99ee33871b72b2",
            "f7dc0bcf734a40549ff31d785ac4119d",
            "ec5dea8b61524b52957fb25064936375",
            "6cede445c1d9434480f73ac3b2d3b7d6",
            "df660fdbe5f84e02be8ea3c4534c5340",
            "fda6d2099b9b49f4ba9b73e0d63eb8a5",
            "d5cedb48db1140189c383041f7d1fe9a",
            "964784efb3864cc3a426c68b4e459ef3",
            "4320b6d9d2614bfea9cfb0166d1a4630",
            "b278bd7ada644b16976f3b581df587f0",
            "55843649edd14d8cb6eea61c344df97f",
            "cf1b2c6731c8470384a782a13d5b948e",
            "b42c004526c2432ea043c78c44cd6025",
            "e58fca07a4784165b10e2585e5149de8",
            "9b4604c2962a445798dd9769ab4420a9",
            "dd2a897d212044f0b2b1094b32af5a3f",
            "d3ae338153a84bfbb4e902b01035f58e",
            "e3534e15740942be9eff919d747f5502",
            "1ad00c64bf264a798ad5548acdfa95c4",
            "fce42dba304043daab4952ae81721753",
            "5e3478715a954dfda63a023e72fd38e6",
            "530541c9c6c948f98bd2a780ce64b790",
            "d5ca996721f94af0a0cd0567f5a1a582",
            "ce139bccc3014b22ad60b5d8a05898fc",
            "7acecf5e7e96491d864971a16e03e9ab",
            "f26ac116707449e79ae92df939dd3afe",
            "f623a5eee3914a77a2d5b27d1c2f2816",
            "b4f9b5f8cc6c4a669d2258f3a412912b",
            "8a00e84bc60c4bd6baf468690c8d1664",
            "646411aa347d41088e59cf6170a486ed",
            "f7ac8e34ad6945b1892b4bf540d4a5ff",
            "5b25b80dc40942059de77dbe2ba69f36",
            "223969d3127a4825bc20ca6018a95bfa",
            "4143495945684d3fbe94c44044335534",
            "3ad7510ed15f4ccd9bae9da2bb329f98",
            "f022697f6edb4b45adb12db397f0564c",
            "9ac5cfbde9004763ba8e00b2d877d419",
            "443ef92d1b18464089d29b461b5b2a6e",
            "10fa431aa6d24b5c861496a7429ede92",
            "b7b3ed5d18c04c489bb6b11be7879ce2",
            "98d4675731764b9691a0d8df5afb6058",
            "53babc26d977412e94bd7229dacb51f4",
            "c49227a53369411d8c8bed18366364eb",
            "8bb37833cedd477384d214a3494bca72",
            "a2bf76ff4ead4d33ba79e8f8e63275d6",
            "ea60d659547b4841b3f63981eaea176e",
            "29b0c7613e51489ebe205f8af5fc3597",
            "b6f3e2a1d28d4ef580eb2db4134da244",
            "ffb44d2aeed4401997d00a0338eba1fa",
            "fbd3ef60949d42deb860b4cb55399874",
            "896124ad35f74a59a87f3b3e02473a70",
            "00dec712ee6d49d285cbfa9b96d71af0",
            "f31014cfdb294f44adf6b3a9974eb696",
            "ed2b79bb314a439da187be3ad1a6ad51",
            "4c22aa362cd948049492db9cc46ec9db",
            "4a1bf7a81af746248f3d684b5a8039df",
            "1c9ecce3dd5b4ccd93435ce01d6009f8",
            "62f185a1d11e449998dfb7b9daa6d389",
            "83e790f0aa264d56b77f8da475ce08e7",
            "413c478d9b2747e7a948d07ddfda0e27",
            "3f0b1121084d4ffd8d7166d484b851af",
            "77626f629d5f4f6eb7e79883a34a373e",
            "f648d4cad16e4c8f9a243e0466ced926",
            "98872d4f25f942eba8c1e477c9e9ceef",
            "0a65d6db64c040ff936787deff507784",
            "47133b2f20614be498b3b9603f2078d6",
            "d6d9e4be8fde490a904ff11c42090a0e",
            "2c053f2ff0bc4156917cee68de848723",
            "c99c2ea8b3784a96a880d9f3491acdcd",
            "733d0da4817d4b39b7eaf4c196913d2e",
            "0ff11bc47ffa4a5bac8d3e1e31f49137",
            "d80eabdbaf0d43e882c769e53c9ba4be",
            "e78a2daea9924fcfab0a694f3e9e4a82",
            "cbaeab6730154d02821c90de95e5d18b",
            "eaaf3f9f2e174f9b9efd963ca2ed591d",
            "7ffca225ffeb4f6b83b85763a3d3560e"
          ]
        },
        "id": "SUJpMIRDFdLD",
        "outputId": "534c529a-2b04-4f7a-9b3c-f20df017ca93"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4a609cb765cd4cddb4e11d0d00eac7de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55843649edd14d8cb6eea61c344df97f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "530541c9c6c948f98bd2a780ce64b790",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "added_tokens.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "223969d3127a4825bc20ca6018a95bfa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8bb37833cedd477384d214a3494bca72",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c22aa362cd948049492db9cc46ec9db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "47133b2f20614be498b3b9603f2078d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Sakshi-1234/NLPFinal\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Sakshi-1234/NLPFinal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1Nkb78eM7D5",
        "outputId": "538c6e35-810d-40d8-cfaf-c5624e03e317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "article:  sometimes you may feel sad or lonely and that is normal . try not to let your sadness affect your college or high school experience , though . it is essential for you to get involved with campus and school activities and to make new friends . dont let your schoolwork slide , even though you might feel lonely at first . try to make friends in each of your classes . if you are feeling down , get together with a friend or call your partner . if you are in a relationship with someone , you need to trust them . this will be one of the biggest challenges of maintaining a long distance relationship when your partner goes to a different school . its easy to assume your partner is out partying or cheating on you if you arent seeing them everyday . try not to allow negative thoughts to affect your trust in the other person . know that long distance couples who stay together are statistically more likely to stay together than traditional couples . their relationship has been tested by long distance and couples who have been in a long distance relationship are more likely to have developed strategies for working through difficult times . , this is especially important , as college will be a challenging new experience for both of you . college is a very emotional and challenging time , especially for new students . you and your partner are going to have new experiences . talk frequently about what is going on with each other . high school is a particularly challenging phase of life involving new social situations , new experiences , and new freedoms . communicate with your girlfriendboyfriend about what is going on . classes and new social situations can be particularly hard for new college students . know that your partner is going through the same thing and talk about your experiences . college is about finding new passions , learning new things , and making new friends . join a club or social group that deals with your interests . most colleges have societies or clubs religious groups , the arts , sports , and other hobbies . get to know your roommates and classmates . you will find people with common interests and make lasting friendships . dive into your schoolwork . remember , you went to high school or college to get a diplomadegree and you will need to work hard . take classes seriously and challenge yourself\n",
            "Summary: you may feel sad or lonely and that is normal. try not to let your sadness affect your college or high school experience. it is essential for you to get involved with campus and school activities.\n"
          ]
        }
      ],
      "source": [
        "def generate_summary(text, max_input_length=512, max_summary_length=128, num_beams=4):\n",
        "    \"\"\"\n",
        "    Generates a summary for a single text input.\n",
        "    \"\"\"\n",
        "    # Tokenize input\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        max_length=max_input_length,\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "    # Generate summary tokens\n",
        "    summary_ids = model.generate(\n",
        "      input_ids=inputs[\"input_ids\"],\n",
        "      attention_mask=inputs[\"attention_mask\"],\n",
        "      max_length=128,\n",
        "      num_beams=6,\n",
        "      early_stopping=True,\n",
        "      repetition_penalty=2.0,\n",
        "      length_penalty=1.0,\n",
        "      no_repeat_ngram_size = 3,\n",
        "    )\n",
        "\n",
        "\n",
        "    # Decode tokens to string\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n",
        "\n",
        "# Example usage\n",
        "article = X_test[90]\n",
        "print(\"article: \", article)\n",
        "summary = generate_summary(article)\n",
        "print(\"Summary:\", summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIHJYd6M9K3N"
      },
      "source": [
        "# Postprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJiRTn5MNCiW",
        "outputId": "f3767abc-a119-4592-d25c-188aa2353778"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned Summary: you may feel sad or lonely and that is normal. try not to let your sadness affect your college or high school experience. it is essential for you to get involved with campus and school activities.\n"
          ]
        }
      ],
      "source": [
        "def clean_summary(summary_text):\n",
        "    # Strip leading/trailing whitespace\n",
        "    summary_text = summary_text.strip()\n",
        "\n",
        "    # Optional: replace multiple spaces/newlines with a single space\n",
        "    summary_text = ' '.join(summary_text.split())\n",
        "\n",
        "    # Optional: additional cleaning logic\n",
        "    # e.g., remove unwanted characters, fix punctuation\n",
        "\n",
        "    return summary_text\n",
        "\n",
        "# Apply postprocessing\n",
        "cleaned_summary = clean_summary(summary)\n",
        "print(\"Cleaned Summary:\", cleaned_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTwioIYa9R-5"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oeOtaOuNTWqx",
        "outputId": "67bac6d4-e427-4729-80fc-2c78dc0f31fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge_score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=c9993bc9bdb7d2f2975cffbc163c00b136f562c038e2b653afbed0fc6cfae9c0\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: rouge_score\n",
            "Successfully installed rouge_score-0.1.2\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.6.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.36.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.11.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n"
          ]
        }
      ],
      "source": [
        "!pip install rouge_score\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "46cf53e29b9148bbaeebf5e6e3d2be03",
            "455dab72f268421d8942cb3fea0510ca",
            "e8ddfe1c16714ca2a2813c690a0d4549",
            "e73b3d96a48b44d2be9400b8bcb7772d",
            "855ded5a8d7e45d983095874a8d6fe22",
            "8ac4392cab034453bb01286f3f74da03",
            "447369ae54664cfd824c744d8a16ac58",
            "bfca6657cf904db3b2ae8dca4b590b94",
            "57942b5e3c1f4cce865c198ba1421d79",
            "25976eba74e74eed91771859dc45ddb4",
            "09a48a5a7b5346678c2f519e0a780c16"
          ]
        },
        "id": "Ks2G8MuINF4e",
        "outputId": "b5af2a3a-6b2a-4fbd-fb32-356df293acfc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46cf53e29b9148bbaeebf5e6e3d2be03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'rouge1': np.float64(0.23516481017125038), 'rouge2': np.float64(0.05041304553955303), 'rougeL': np.float64(0.15475740596492243), 'rougeLsum': np.float64(0.1542438586047078)}\n"
          ]
        }
      ],
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL', 'rougeLsum'])\n",
        "\n",
        "reference_summary = y_test[random_int]\n",
        "candidate_summary = summary\n",
        "\n",
        "# print(\"Reference Summary:\", reference_summary)\n",
        "# print(\"Candidate Summary:\", candidate_summary)\n",
        "\n",
        "scores = scorer.score(reference_summary, candidate_summary)\n",
        "scores_wrapped = fill(str(scores), width=80)\n",
        "print(scores_wrapped)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "xUZ77w5d9BCd"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
